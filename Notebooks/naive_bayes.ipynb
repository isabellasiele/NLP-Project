{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e417f30",
   "metadata": {},
   "source": [
    "## This is an basic implementation of naives bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63448d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so fist thing is understanding what the standard bayes classifier is doing\n",
    "import numpy as np\n",
    "\n",
    "class BayesianClassifier:\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "        # the class priors and likelihoods will be stored here\n",
    "        # class_priors is a dictionary mapping class labels to their prior probabilities\n",
    "        # for example, {0: 0.6, 1: 0.4} if there are two classes 0 and 1\n",
    "\n",
    "\n",
    "        self.class_priors = {}\n",
    "\n",
    "        # likelihoods is a dictionary mapping class labels to their likelihood parameters\n",
    "        # the likelihoods parameters is the mean and variance for each feature given the class\n",
    "        # so look at it like this:\n",
    "        #       {0: {'mean': [mean1, mean2, ...], \n",
    "        #       'var': [var1, var2, ...]}, 1: {...}}\n",
    "\n",
    "        # so the dictionary structure is like this\n",
    "        # class_label -> {'mean': [...], 'var': [...]}\n",
    "        # 0 or 1 -> {'mean' : [mean0, mean1], 'var': [var0, var1]}\n",
    "\n",
    "        # where the mean of the class 0 and variance of class 0 are stored in lists\n",
    "        # so to access it would something like this: \n",
    "        # self.likelihoods[0]['mean'] to get the mean vector for class 0\n",
    "        # self.likelihoods[1]['var'] to get the variance vector for class 1\n",
    "\n",
    "        self.likelihoods = {}\n",
    "\n",
    "\n",
    "        # store the unique classes so in this case 0 and 1\n",
    "\n",
    "        self.classes = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # get the unique classes\n",
    "\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        # total number of samples\n",
    "\n",
    "        total_samples = len(y)\n",
    "\n",
    "        #\n",
    "        for cls in self.classes:\n",
    "            # so this gets all the classes in terms of same based on the y labels\n",
    "            # so for some X_cls[i] is the list of samples that belong to class cls\n",
    "            X_cls = X[y == cls]\n",
    "            \n",
    "            # the probability is the frequency of the class in the dataset\n",
    "            self.class_priors[cls] = len(X_cls) / total_samples\n",
    "            # and then we store the mean of each feature \n",
    "            self.likelihoods[cls] = {\n",
    "                # X_cls is all the samples that belong class cls and \n",
    "                \n",
    "                'mean': np.mean(X_cls, axis=0),# this will returns the mean of each class feature as a list\n",
    "                'var': np.var(X_cls, axis=0)# this will return the variance of each class feature as a list\n",
    "            }\n",
    "\n",
    "    def _gaussian_likelihood(self, x, mean, var):\n",
    "        # this in mathematical terms is the probability density function of a normal distribution\n",
    "        # the probability density function is given by:\n",
    "        # P(x|mean, var) = (1 / sqrt(2 * pi * var)) * exp(-((x - mean)^2) / (2 * var))\n",
    "        exponent = np.exp(-((x - mean) ** 2) / (2 * var))\n",
    "        normalization = (1 / np.sqrt(2 * np.pi * var))\n",
    "        return normalization * exponent\n",
    "\n",
    "    def predict(self, X):\n",
    "        # list predictions will contain predicted class labels for each sample in X\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            #\n",
    "            class_probs = {}\n",
    "            for cls in self.classes:\n",
    "                # the prior are all the possible y values\n",
    "                prior = self.class_priors[cls]\n",
    "                # likehood per feature\n",
    "                # so the gaussian likelihood returns the a list of likelihood of each feature\n",
    "                likelihood = np.prod(self._gaussian_likelihood(x, \n",
    "                                                                self.likelihoods[cls]['mean'], \n",
    "                                                                self.likelihoods[cls]['var']))\n",
    "                class_probs[cls] = prior * likelihood\n",
    "            predictions.append(max(class_probs, key=class_probs.get))\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    # this is a better production ready version of predict based on the log probabilities\n",
    "    def predict_log(self, X):\n",
    "        predictions = []\n",
    "        # so for each sample in X\n",
    "        for x in X:\n",
    "            class_log_prob = {}\n",
    "            # get the probabiteis of each class\n",
    "            for cls in self.classes:\n",
    "                # so the log values make it easir to compute since instead of multplication we do \n",
    "                # addition and for extremly small values that would underflow become stable\n",
    "                log_prior = np.log(self.class_priors[cls])\n",
    "                # so the gausian likelihood of each feature given the class\n",
    "                # this is a list of likelihood that in regards to some class variable y\n",
    "                likelihoods = self._gaussian_likelihood(x,self.likelihoods[cls]['mean'], self.likelihoods[cls]['var'])\n",
    "                log_likelihood = np.sum(np.log(likelihoods))\n",
    "                class_log_prob[cls] = log_prior + log_likelihood\n",
    "            predictions.append(max(class_log_prob, key=class_log_prob.get))\n",
    "        return np.array(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
